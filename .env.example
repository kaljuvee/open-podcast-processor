# Groq API Configuration
# Get your API key from https://console.groq.com/
GROQ_API_KEY=your-groq-api-key-here

# Groq Model Configuration
# Options: llama-3.3-70b-versatile (default, 131k context), llama-3.1-8b-instant, llama-3.1-70b-versatile, etc.
# See https://console.groq.com/docs/models for available models
GROQ_MODEL=llama-3.3-70b-versatile

# Groq Whisper Model Configuration
# Options: whisper-large-v3-turbo (default), whisper-large-v3
# See https://console.groq.com/docs/models for available Whisper models
GROQ_WHISPER_MODEL=whisper-large-v3-turbo

# Groq Temperature Configuration
# Temperature for reasoning/summarization (0.0 to 2.0)
# Lower values = more focused/deterministic, Higher values = more creative
GROQ_TEMPERATURE=0.2

# Groq Topic Analysis Temperature
# Temperature for topic analysis (0.0 to 2.0)
GROQ_TOPIC_TEMPERATURE=0.3

# Groq Max Tokens Configuration
# Maximum tokens in response (default: 4000)
GROQ_MAX_TOKENS=4000

# PostgreSQL Database Configuration
# Format: postgresql://user:password@host:port/database
DB_URL=postgresql://user:password@localhost:5432/podcast_db

# PostgreSQL Schema Configuration
# Schema name (default: public)
DB_SCHEMA=public
